{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc3cc04",
   "metadata": {},
   "source": [
    "# Time-series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db92a3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "eb5717d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61b7dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "packetLossRate = np.random.random((100,))\n",
    "jitter = np.arange(100)\n",
    "latency = np.random.random((100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a63818e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "current = datetime.now()\n",
    "times = [(current + timedelta(seconds=i)).strftime(\"%Y-%m-%d %H:%M:%S\") for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fdf390fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'packetLossRate': packetLossRate,\n",
    "    'jitter': jitter,\n",
    "    'latency': latency,\n",
    "    'timestamp': times\n",
    "})\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8491613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.pop('timestamp')\n",
    "ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "      data=df,\n",
    "      targets=None,\n",
    "      sequence_length=21,\n",
    "      sequence_stride=1,\n",
    "      shuffle=False,\n",
    "      batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "078685e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "42496724",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_width, label_width, shift=0,\n",
    "                 train_df=None, val_df=None, test_df=None,\n",
    "                 input_columns=None, label_columns=None, timestamp_column='timestamp'):\n",
    "\n",
    "        # Store the raw data\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.input_columns = input_columns\n",
    "        self.label_columns = label_columns\n",
    "        self.timestamp_column = timestamp_column\n",
    "        if input_columns is not None:\n",
    "            self.input_columns_indices = {name: i for i, name in enumerate(input_columns)}\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift + label_width\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.input_columns is not None:\n",
    "            inputs = tf.stack(\n",
    "                [inputs[:, :, self.column_indices[name]] for name in self.input_columns],\n",
    "                axis=-1\n",
    "            )\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1\n",
    "            )\n",
    "\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, len(self.input_columns)])\n",
    "        labels.set_shape([None, self.label_width, len(self.label_columns)])\n",
    "\n",
    "        return inputs, labels\n",
    "    \n",
    "    def make_dataset(self, data, shuffle=True):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=shuffle,\n",
    "            batch_size=1\n",
    "        )\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "    \n",
    "    def plot(self, sample_set, plot_col, model=None, max_subplots=3):\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        for inputs, outputs in sample_set.take(max_subplots):\n",
    "            plt.subplot(max_subplots, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [normed]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "                label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "\n",
    "        plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                    edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "        if model is not None:\n",
    "            predictions = model(inputs)\n",
    "            plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                      marker='X', edgecolors='k', label='Predictions',\n",
    "                      c='#ff7f0e', s=64)\n",
    "\n",
    "        if n == 0:\n",
    "            plt.legend()\n",
    "\n",
    "        plt.xlabel('Time [sec]')\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f66328a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=(TensorSpec(shape=(None, 20, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = WindowGenerator(20, 2, 1, train_df=df, input_columns=['jitter', 'packetLossRate', 'jitter'], label_columns=['packetLossRate', 'jitter'])\n",
    "s1.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "df02d644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[20.          0.04142274 20.        ]\n",
      "  [21.          0.93170613 21.        ]\n",
      "  [22.          0.26347166 22.        ]\n",
      "  [23.          0.49446526 23.        ]\n",
      "  [24.          0.09528789 24.        ]\n",
      "  [25.          0.8497314  25.        ]\n",
      "  [26.          0.752091   26.        ]\n",
      "  [27.          0.42919093 27.        ]\n",
      "  [28.          0.48214233 28.        ]\n",
      "  [29.          0.33425155 29.        ]\n",
      "  [30.          0.22185107 30.        ]\n",
      "  [31.          0.5295909  31.        ]\n",
      "  [32.          0.15594777 32.        ]\n",
      "  [33.          0.9462705  33.        ]\n",
      "  [34.          0.9260007  34.        ]\n",
      "  [35.          0.88813335 35.        ]\n",
      "  [36.          0.5067773  36.        ]\n",
      "  [37.          0.9992331  37.        ]\n",
      "  [38.          0.7014517  38.        ]\n",
      "  [39.          0.60993737 39.        ]]] [[[ 0.38814342 41.        ]\n",
      "  [ 0.27783567 42.        ]]]\n",
      "[[[7.5000000e+01 1.0215090e-01 7.5000000e+01]\n",
      "  [7.6000000e+01 6.7611349e-01 7.6000000e+01]\n",
      "  [7.7000000e+01 6.3840276e-01 7.7000000e+01]\n",
      "  [7.8000000e+01 7.5262040e-01 7.8000000e+01]\n",
      "  [7.9000000e+01 5.0123948e-01 7.9000000e+01]\n",
      "  [8.0000000e+01 2.8772497e-01 8.0000000e+01]\n",
      "  [8.1000000e+01 4.7310078e-01 8.1000000e+01]\n",
      "  [8.2000000e+01 2.7187470e-01 8.2000000e+01]\n",
      "  [8.3000000e+01 9.5113647e-01 8.3000000e+01]\n",
      "  [8.4000000e+01 1.2285447e-01 8.4000000e+01]\n",
      "  [8.5000000e+01 3.4130183e-01 8.5000000e+01]\n",
      "  [8.6000000e+01 4.9307576e-01 8.6000000e+01]\n",
      "  [8.7000000e+01 9.4034797e-01 8.7000000e+01]\n",
      "  [8.8000000e+01 1.7934333e-01 8.8000000e+01]\n",
      "  [8.9000000e+01 3.6793721e-01 8.9000000e+01]\n",
      "  [9.0000000e+01 7.1269536e-01 9.0000000e+01]\n",
      "  [9.1000000e+01 7.8888702e-01 9.1000000e+01]\n",
      "  [9.2000000e+01 7.4965104e-02 9.2000000e+01]\n",
      "  [9.3000000e+01 4.5645392e-01 9.3000000e+01]\n",
      "  [9.4000000e+01 7.9354048e-01 9.4000000e+01]]] [[[ 0.9479003  96.        ]\n",
      "  [ 0.10656381 97.        ]]]\n"
     ]
    }
   ],
   "source": [
    "for inputs, outputs in s1.train.take(2):\n",
    "    print(inputs.numpy(), outputs.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "709dafa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(None, [1, 2, 3], None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1289a405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0, 1, 2, 3, 4][slice(1, 2, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0a65cc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.random.random(24).reshape(4, 6)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6463cec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(4).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "90562293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80587177, 0.12688409, 0.42749691, 0.27178802, 0.35268006,\n",
       "        0.01014872, 0.        ],\n",
       "       [0.23899643, 0.29177204, 0.28929395, 0.34374339, 0.04585866,\n",
       "        0.05445515, 1.        ],\n",
       "       [0.23098239, 0.65763688, 0.7426619 , 0.92468782, 0.03925473,\n",
       "        0.15305659, 2.        ],\n",
       "       [0.98729009, 0.77883367, 0.99945088, 0.6316951 , 0.52600888,\n",
       "        0.04926711, 3.        ]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack([test, np.arange(4).reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8a8cb845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df, dtype=np.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e04992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:timeseries]",
   "language": "python",
   "name": "conda-env-timeseries-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
